{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import editdistance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "단어 간 거리는 형태적 거리와 의미적 거리로 분류됩니다.\n",
    "\n",
    "- 의미적 거리: Word2Vec(e.g. King == men)\n",
    "- 형태적 거리: Levenshtein distance(edit distance) (e.g. 점심 먹자 -> 저녁 먹자)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Levenshtein (Edit) distance\n",
    "\n",
    "Levenshtein distance 는 한 string s1을 s2로 변환하는 최소 횟수를 두 string 간의 거리로 정의합니다.\n",
    "\n",
    "횟수(거리)는 **삭제, 삽입, 치환**의 연산으로 이루어 집니다.\n",
    "\n",
    "Ref: [Levenshtein (edit) distance 를 이용한 한국어 단어의 형태적 유사성](https://lovit.github.io/nlp/2018/08/28/levenshtein_hangle/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "class CharacterErrorRate(pl.metrics.Metric):\n",
    "    \"\"\"Character error rate metric, computed using Levenshtein distance.\"\"\"\n",
    "    def __init__(self, ignore_tokens: Sequence[int], *args):\n",
    "        super().__init__(*args)\n",
    "        self.ignore_tokens = set(ignore_tokens)\n",
    "        self.add_state(\"error\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")  # pylint: disable=not-callable\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")  # pylint: disable=not-callable\n",
    "        self.error: torch.Tensor\n",
    "        self.total: torch.Tensor\n",
    "\n",
    "    def update(self, preds: torch.Tensor, targets: torch.Tensor) -> None:\n",
    "        N = preds.shape[0]\n",
    "        for ind in range(N):\n",
    "            pred = [_ for _ in preds[ind].tolist() if _ not in self.ignore_tokens]\n",
    "            target = [_ for _ in targets[ind].tolist() if _ not in self.ignore_tokens]\n",
    "        \n",
    "            distance = editdistance.distance(pred, target)\n",
    "            print(f'Distance is {distance}')\n",
    "            error = distance / max(len(pred), len(target))\n",
    "            print(f'Error is {error}')\n",
    "            self.error = self.error + error\n",
    "        self.total = self.total + N\n",
    "        print(f'Total is {self.total}')\n",
    "        print('-'* 80)\n",
    "\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        return self.error / self.total\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "metric = CharacterErrorRate([0, 1])\n",
    "\n",
    "X = torch.tensor(  # pylint: disable=not-callable\n",
    "   [\n",
    "      [0, 2, 2, 3, 3, 1],  # error will be 0\n",
    "      [0, 2, 1, 1, 1, 1],  # error will be .75\n",
    "      [0, 2, 2, 4, 4, 1],  # error will be .5\n",
    "   ]\n",
    ")\n",
    "Y = torch.tensor(  # pylint: disable=not-callable\n",
    "   [\n",
    "      [0, 2, 2, 3, 3, 1],\n",
    "      [0, 2, 2, 3, 3, 1],\n",
    "      [0, 2, 2, 3, 3, 1],\n",
    "   ]\n",
    ")\n",
    "metric(X, Y)\n",
    "print(metric.compute())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Distance is 0\n",
      "Error is 0.0\n",
      "Distance is 3\n",
      "Error is 0.75\n",
      "Distance is 2\n",
      "Error is 0.5\n",
      "Total is 3\n",
      "--------------------------------------------------------------------------------\n",
      "Distance is 0\n",
      "Error is 0.0\n",
      "Distance is 3\n",
      "Error is 0.75\n",
      "Distance is 2\n",
      "Error is 0.5\n",
      "Total is 3\n",
      "--------------------------------------------------------------------------------\n",
      "tensor(0.4167)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Greedy Seaerch Decoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "softmax를 통과한 후에, 가장 확률값이 큰 인덱스를 뽑아 해당 time-step의 y_hat으로 사용하는 것."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![img](https://guillaumegenthial.github.io/assets/img2latex/seq2seq_vanilla_decoder.svg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def greedy_decode(self, logprobs: torch.Tensor, max_length: int) -> torch.Tensor:\n",
    "   \"\"\"\n",
    "   Greedily decode sequences, collapsing repeated tokens, and removing the CTC blank token.\n",
    "   See the \"Inference\" sections of https://distill.pub/2017/ctc/\n",
    "\n",
    "   Using groupby inspired by https://github.com/nanoporetech/fast-ctc-decode/blob/master/tests/benchmark.py#L8\n",
    "\n",
    "   Parameters\n",
    "   ----------\n",
    "   logprobs\n",
    "      (B, C, S) log probabilities\n",
    "   max_length\n",
    "      max length of a sequence\n",
    "\n",
    "   Returns\n",
    "   -------\n",
    "   torch.Tensor\n",
    "      (B, S) class indices\n",
    "      \n",
    "   \"\"\"\n",
    "   B = logprobs.shape[0]\n",
    "   argmax = logprobs.argmax(1)\n",
    "   decoded = torch.ones((B, max_length)).type_as(logprobs).int() * self.padding_index\n",
    "   for i in range(B):\n",
    "      seq = [b for b, _g in itertools.groupby(argmax[i].tolist()) if b != self.blank_index][:max_length]\n",
    "      for ii, char in enumerate(seq):\n",
    "         decoded[i, ii] = char\n",
    "   return decoded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('fsdl-text-recognizer-2021': conda)"
  },
  "interpreter": {
   "hash": "2215377a054c706854901640cd9b0f82e8130586dc822126619e2816a78a3d89"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}